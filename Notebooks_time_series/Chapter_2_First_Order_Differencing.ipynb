{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98d0ac0",
   "metadata": {},
   "source": [
    "# Stationary processes\n",
    "\n",
    "### Properties of data such as central tendency, dispersion, skewness, and kurtosis are called sample statistics. Mean and variance are two of the most commonly used sample statistics.\n",
    "\n",
    "### In any analysis, data is collected by gathering information from a sample of the larger population. Mean, variance, and other properties are then estimated based on the sample data. Hence these are referred to as sample statistics.\n",
    "\n",
    "### An important assumption in statistical estimation theory is that, for sample statistics to be reliable, the population does not undergo any fundamental or systemic shifts over the individuals in the sample or over the time during which the data has been collected. \n",
    "\n",
    "### This assumption ensures that sample statistics do not alter and will hold for entities that are outside the sample used for their estimation.\n",
    "\n",
    "### This assumption also applies to time series analysis so that mean, variance and auto- correlation estimated from the sample can be used as a reasonable estimate for future occurrences. \n",
    "\n",
    "### In time series analysis, this assumption is known as stationarity, which requires that the internal structures of the series do not change over time. \n",
    "\n",
    "### Therefore, stationarity requires mean, variance, and autocorrelation to be invariant with respect to the actual time of observation. \n",
    "\n",
    "### Another way of understanding stationarity is that the series has constant mean and constant variance without any predictable and repetitive patterns.\n",
    "\n",
    "### A popular example of a stationary time series is the zero-mean series which is a collection of samples generated from a normal distribution with mean at zero. The zero-mean series is illustrated in the following figure which is generated from points which are sampled from a normal distribution of zero mean and unit variance. Though points are sequentially sampled from the normal distribution and plotted as a time series, the individual observations are independent and identically distributed (iid). The zero-mean series does not show any temporal patterns such as trend, seasonality and auto-correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f5d9c",
   "metadata": {},
   "source": [
    "![zero_mean](images/zero_mean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ecca8",
   "metadata": {},
   "source": [
    "### However, most real-life time series are not stationary. Non-stationarity mostly arises due to the presence of trend and seasonality that affects the mean, variance, and autocorrelation at different points in time. \n",
    "\n",
    "### However, it is noteworthy that we have not included cyclical fluctuations while defining stationarity. This is because crests and troughs due to cyclical changes do not occur at fixed intervals and therefore can be explained only by exogenous variables. \n",
    "\n",
    "### In general, a time series with no predictable patterns in the long run (without considering exogenous factors as explanatory variables of course!) is stationary.\n",
    "\n",
    "### An crucial step in time series analysis is statistically verifying stationarity and destationarizing a non-stationary time series through special mathematical operations. \n",
    "\n",
    "## To this end, we will discuss the Augmented Dickey-Fuller (ADF) test for detecting stationarity and describe the method of differencing for destationarizing non-stationary time series.\n",
    "\n",
    "## Differencing can remove trend and seasonal components. The methods of decomposition to develop models of trend and seasonality for complex time series, is discussed in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b1251",
   "metadata": {},
   "source": [
    "# Differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d005e",
   "metadata": {},
   "source": [
    "### The basic idea of differencing is taking differences between successive occurrences of the time series Δxt = xt - xt-1 such that Δxt have constant mean and variance and hence can be treated as a stationary series.\n",
    "\n",
    "### The ADF test is based on the idea of differencing the original time series and therefore we will explain it after discussing various types of differencing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb1749",
   "metadata": {},
   "source": [
    "## First-order differencing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f36030",
   "metadata": {},
   "source": [
    "### First order differencing implies taking differences between successive realizations of the time series so that the differences Δxt are irregular variations free from any long run trend or seasonality. \n",
    "\n",
    "### The random walk model discussed in the last chapter is a sum of subsequent random variations and is given by xt = xt-l + Єt where Єt is a zero mean random number from normal distribution. \n",
    "\n",
    "### Random walks are characterized by long sequence of upward or downward trends. Besides, they take unforeseen changes in direction. Based on these characteristics, random walks are non-stationary. However, the first differences Δxt of a random walk are equal to the random noise Єt. \n",
    "\n",
    "### Hence the residuals remaining after first- order differencing of a random walk is a zero-mean stationary series. The transformed time series, obtained by taking first order differences is denoted as follows:\n",
    "\n",
    "     x't = xt - xt-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8afdf9",
   "metadata": {},
   "source": [
    "### The transformed time series has N-1 observations with zero mean and constant variance. This model assumes the starting value is x1 = 0. The starting value can be generalized to x1 = 0 and hence the the differenced time series would be:\n",
    "\n",
    "    x't = xt - xt-1 = c + Єt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155ea53",
   "metadata": {},
   "source": [
    "### If the starting value x1 = 0 is positive, the random walk tends to drift upwards while if it is negative, the drift goes downward.\n",
    "\n",
    "### As evident from the preceding discussion that the first-order differences are independent and identically distributed with a constant mean and a constant variance and hence have no autocorrelation.\n",
    "\n",
    "### A quick way to verify whether the first-order differencing has stationarized a time series is to plot the ACF function and run the Ljung-Box test for the differenced series. The Ljung- Box test determines if the observed auto-correlation is statistically significant. \n",
    "\n",
    "### The null hypothesis of the Ljung-Box test is that the time series consist of random variations and lacks predictable autocorrelation while the alternate hypothesis proposes that the observed autocorrelation is not random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240337cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
